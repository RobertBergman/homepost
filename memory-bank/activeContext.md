# Active Context

_Current work focus, recent changes, next steps, active decisions, important patterns, and learnings._

## Current Focus
- Integrating OpenAI-powered AI assistant features
- Implementing real-time WebSocket communication
- Developing device management capabilities
- Building audio processing and TTS features
- Ensuring cross-platform compatibility, especially Windows
- Expanding automated test coverage

## Recent Changes
- Scaffolded backend and frontend structure
- Added initial OpenAI, LangChain, and LangGraph integration points
- Set up WebSocket communication framework
- Created Windows-specific install and patch scripts
- Developed initial test suites with Jest and mocks

## Next Steps
- Complete AI assistant integration workflows
- Finalize device management features
- Polish frontend UI and UX
- Optimize audio processing pipeline
- Harden WebSocket communication
- Expand and refine test coverage
- Prepare deployment scripts and documentation

## Active Decisions
- Use OpenAI APIs as primary AI provider
- Leverage LangChain and LangGraph for AI orchestration
- Maintain modular separation of backend and frontend
- Prioritize cross-platform support from the start
- Emphasize automated testing

## Important Patterns and Preferences
- Modular, service-oriented backend design
- Component-based React frontend
- Observer pattern for real-time updates
- Adapter pattern for external API integrations
- Consistent code style enforced via linters (planned)

## Learnings and Insights
- Cross-platform audio handling requires special attention
- OpenAI integration benefits from LangChain orchestration
- WebSocket communication is critical for real-time UX

## Open Questions
- How to handle user authentication and authorization
- Best approach for device discovery and onboarding
- Strategies for offline or degraded mode operation

## Initial Notes
This context is inferred from project structure and should be updated as development progresses.
